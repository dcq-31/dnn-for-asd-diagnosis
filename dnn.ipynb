{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural network for ASD classification using resting-state fMRI\n",
    "\n",
    "This notebook evaluate a deep neural network for ASD diagnosis using functionañ time series data from brain regions of interest. The used resting-state fMRI data from the ABIDE dataset were preprocessed by the **Preprocessed Connectome Project (PCP)** using four pipelines, involving 1100 subjects from multiple international sites.\n",
    "\n",
    "### Configure the loading data\n",
    "\n",
    " The variables necessary for loading the neuroimaging data are defined. The `pipeline` and `atlas` used for preprocessing and ROIs extraction, also the `phenotypic` information included are specified. Additionally, list all neuroimaging sites available in the dataset and those that are to be included in the analysis are selected using the `sites` and `test_site` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = 'cpac'  \n",
    "rois = 'rois_ho'\n",
    "phenotypic = 'all_cases'\n",
    "\n",
    "# List of all available neuroimaging sites in the dataset\n",
    "all_sites = [\n",
    "    'caltech', 'cmu', 'kki', 'leuven_1', 'leuven_2', 'max_mun', 'nyu', \n",
    "    'ohsu', 'olin', 'pitt', 'sbl', 'sdsu', 'stanford', 'trinity', \n",
    "    'ucla_1', 'ucla_2', 'um_1', 'um_2', 'usm', 'yale'\n",
    "]\n",
    "\n",
    "# Sites include in the analysis\n",
    "sites = all_sites\n",
    "\n",
    "# Designated site for external testing\n",
    "test_site = 'yale'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROIs data loading function\n",
    "\n",
    "Definition of the `load_rois_data(pipeline, rois, sites, phenotypic)` function to retrieve subject time series and diagnostic labels from each neuroimaging site in `sites`. This function reads `phenotypic` information from CSV files, then loads the time series data for each subject. Also handle potential issues, such as missing files or NaN values, to ensure data integrity before analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_rois_data(pipeline, rois, sites, phenotypic):\n",
    "    \"\"\"\n",
    "    Loads time series and diagnostic labels from neuroimaging data files for the specified sites.\n",
    "    \n",
    "    Parameters:\n",
    "        pipeline (str): Preprocessing pipeline used for the data.\n",
    "        rois (str): Atlas defining regions of interest.\n",
    "        sites (list of str): List of site names to load data from.\n",
    "\n",
    "    Returns:\n",
    "        rois_time_series (dict): Contains time series data for each site.\n",
    "        rois_labels (dict): Contains diagnostic labels for each site.\n",
    "    \"\"\"\n",
    "\n",
    "    rois_time_series = {}  # Dictionary to store time series data for each site\n",
    "    rois_labels = {}  # Dictionary to store labels for each site\n",
    "\n",
    "    for site in sites:\n",
    "        # Define path for phenotypic data for the current site\n",
    "        phenotypic_path = f\"data/phenotypic/{phenotypic}/{site}/phenotypic.csv\"\n",
    "\n",
    "        try:\n",
    "            with open(phenotypic_path, 'r') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                site_time_series = []  # List to store time series for each subject at the site\n",
    "                site_labels = []  # List to store labels for each subject at the site\n",
    "\n",
    "                for row in reader:\n",
    "                    file_id = row['file_id']  # Unique subject identifier\n",
    "                    dx_group = row['dx_group']  # Diagnostic group (ASD=1, Control=0)\n",
    "\n",
    "                    # Define path for the time series data file\n",
    "                    data_file_path = os.path.join(f\"data/{pipeline}/{rois}/{site}/{file_id}_{rois}.1D\")\n",
    "\n",
    "                    # Check if the data file exists\n",
    "                    if not os.path.exists(data_file_path):\n",
    "                        print(f\"File Not Found Error: Data file not found at path {data_file_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    data = np.loadtxt(data_file_path)\n",
    "\n",
    "                    # Check for NaN values and add time series to the site list\n",
    "                    if np.isnan(data).any():\n",
    "                        print(f\"Value Error: NaN value found for subject {file_id}\")\n",
    "                    else:\n",
    "                        site_time_series.append(data)\n",
    "                        site_labels.append(1 if dx_group == '1' else 0)  # Assign 1 for ASD, 0 for control\n",
    "\n",
    "                # Store loaded data for the current site in the dictionaries\n",
    "                rois_time_series[site] = site_time_series\n",
    "                rois_labels[site] = np.array(site_labels)\n",
    "                print(f\"Loaded {len(site_time_series)} subjects from site {site}.\")\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File Not Found Error: Phenotypic data not found for site {site}\")\n",
    "\n",
    "    return rois_time_series, rois_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data to be used in the analysis based on specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 38 subjects from site caltech.\n",
      "Loaded 27 subjects from site cmu.\n",
      "Loaded 55 subjects from site kki.\n",
      "Loaded 29 subjects from site leuven_1.\n",
      "Loaded 35 subjects from site leuven_2.\n",
      "Loaded 57 subjects from site max_mun.\n",
      "Loaded 184 subjects from site nyu.\n",
      "Loaded 28 subjects from site ohsu.\n",
      "Loaded 36 subjects from site olin.\n",
      "Loaded 57 subjects from site pitt.\n",
      "Loaded 30 subjects from site sbl.\n",
      "Loaded 36 subjects from site sdsu.\n",
      "Loaded 40 subjects from site stanford.\n",
      "Loaded 49 subjects from site trinity.\n",
      "Loaded 73 subjects from site ucla_1.\n",
      "Loaded 26 subjects from site ucla_2.\n",
      "Loaded 108 subjects from site um_1.\n",
      "Loaded 35 subjects from site um_2.\n",
      "Loaded 101 subjects from site usm.\n",
      "Loaded 56 subjects from site yale.\n"
     ]
    }
   ],
   "source": [
    "rois_time_series, rois_labels = load_rois_data(pipeline, rois, sites, phenotypic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent space embedding\n",
    "\n",
    "This method allows the translation of connectivity matrices from fMRI data into a form that is compatible with Euclidean machine learning techniques while preserving the important geometric properties of the data. Is particularly useful when analyzing covariance or correlation matrices in tasks involving brain connectivity and classification of neurological conditions.\n",
    "\n",
    "The workflow involves two main steps:\n",
    "\n",
    "**Estimate the reference tangent space**: Calculate the tangent space projection based on the mean covariance matrix of a training population. This establishes the \"reference space\" against which individual test subjects can later be projected.\n",
    "\n",
    "**Project subjects onto the reference space**: Using the precomputed reference tangent space from the population, can be project the covariance matrix of a new subjects onto this space. This will yield a tangent space connectivity matrix for the subjects that aligns with those of the population.\n",
    "\n",
    "#### Create training population function\n",
    "\n",
    "Definition of the `create_population(time_series_data)` function for combine the time series into array. To maintain a separate testing set, we exclude the `test_site` site data from the main population data used for estimate the reference tangent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_population(time_series_data):\n",
    "    # Initialize an empty list for the population data \n",
    "    population_data = []\n",
    "\n",
    "    # Loop through the time series data\n",
    "    for item in time_series_data:\n",
    "        # Extend each item\n",
    "        population_data.extend(item)\n",
    "\n",
    "    print(f\"Total subjects in population data: {len(population_data)}\")\n",
    "    return population_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to estimating tangent space functional connectivity\n",
    "\n",
    "Definition of the `estimate_tangent_space(data)` function calculate the tangent space based on the geometric mean covariance matrix of a training population dataset. This creates a \"reference space\" that reflects the average connectivity patterns across the population.\n",
    "\n",
    "The tangent space representation of functional connectivity is a powerful tool for analyzing brain connectivity. It allows the comparison of individual functional connectivity matrices in a standardized space, computed relative to a group average matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "def estimate_tangent_space(data):\n",
    "    \"\"\"\n",
    "    Estimate the tangent space functional connectivity.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : list or ndarray\n",
    "        List or array of time series data for the training population, where each entry corresponds \n",
    "        to a subject's time series (time points x regions).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ConnectivityMeasure\n",
    "        Fitted ConnectivityMeasure object configured for tangent space transformation.\n",
    "    \"\"\"\n",
    "    # Instantiate ConnectivityMeasure for tangent space, vectorizing and discarding the diagonal\n",
    "    connectivity_measure = ConnectivityMeasure(kind='tangent', vectorize=True, discard_diagonal=True)\n",
    "\n",
    "    # Fit the measure on the population data to establish a reference tangent space\n",
    "    connectivity_measure.fit(data)\n",
    "\n",
    "    return connectivity_measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep neural network model building function\n",
    "\n",
    "Definition of the `build_model(input_shape)` function create DNN models with the following architecture:\n",
    "\n",
    "Input Layer: Takes in the number of features from the input data.\n",
    "\n",
    "Dense Layer 1: 128 neurons, ReLU activation, with L2 regularization to reduce overfitting.\n",
    "\n",
    "Dense Layer 2: 64 neurons, ReLU activation, L2 regularization.\n",
    "\n",
    "Output Layer: A single neuron with sigmoid activation for binary classification.\n",
    "\n",
    "The model is compiled with the Adam optimizer and binary cross-entropy loss, as we aim to classify subjects into two classes. We also include accuracy as a performance metric to track model performance during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, regularizers\n",
    "\n",
    "# Define the deep neural network model architecture\n",
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Builds and compiles a deep neural network model for binary classification.\n",
    "\n",
    "    Parameters:\n",
    "    - input_shape: int, the shape of the input layer, matching the number of features in the dataset\n",
    "\n",
    "    Returns:\n",
    "    - model: compiled Keras Sequential model ready for training\n",
    "    \"\"\"\n",
    "    \n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(layers.InputLayer(input_shape=input_shape))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Hidden layers\n",
    "    model.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    # Output layer for binary classification (ASD vs. Healthy)\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of training callbacks\n",
    "\n",
    "To optimize training, we set up three callbacks:\n",
    "\n",
    "**EarlyStopping:** Stops training if validation loss doesn't improve for 10 epochs, preventing overfitting and restoring the best weights.\n",
    "\n",
    "**ReduceLROnPlateau:** Reduces the learning rate by 50% when validation loss plateaus for 5 epochs, ensuring gradual and effective model convergence.\n",
    "\n",
    "**ModelCheckpoint:** Saves the model with the best validation loss to 'best_model.keras', allowing easy access to the optimal version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "# Early stopping to prevent overfitting by stopping training when validation loss stops improving\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',             # Monitor validation loss for early stopping\n",
    "    patience=10,                    # Stop training if val_loss does not improve for 10 epochs\n",
    "    restore_best_weights=True       # Restore the model weights from the epoch with the lowest val_loss\n",
    ")\n",
    "\n",
    "# Reduce learning rate when the validation loss plateaus\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',             # Monitor validation loss for learning rate reduction\n",
    "    factor=0.5,                     # Reduce learning rate by a factor of 0.5\n",
    "    patience=5,                     # Trigger after 5 epochs without improvement in val_loss\n",
    "    min_lr=1e-5                     # Set a floor on the learning rate to avoid overly small values\n",
    ")\n",
    "\n",
    "# Save the best model based on validation loss\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_model.keras',             # Filename for the best model\n",
    "    monitor='val_loss',             # Monitor validation loss for checkpoint saving\n",
    "    save_best_only=True             # Only save the model when it achieves a new best val_loss\n",
    ")\n",
    "\n",
    "# Callbacks list passed to the model\n",
    "callbacks_list = [early_stopping, reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust class balance function\n",
    "\n",
    "Definition of the `adjust_class_balance(indices, labels)` function for ensures equal representation of all classes by undersampling the majority class(es). This is particularly important in supervised learning, where imbalanced classes can lead to biased models. The function return shuffled list of indices representing a class-balanced subset of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def adjust_class_balance(indices, labels):\n",
    "    \"\"\"\n",
    "    Adjusts the balance of classes by undersampling the majority class.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    indices : list or ndarray\n",
    "        Indices of the dataset.\n",
    "    labels : list or ndarray\n",
    "        Class labels corresponding to the indices.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    balanced_indices : ndarray\n",
    "        Indices of the balanced dataset.\n",
    "    \"\"\"\n",
    "    # Class labels to consider\n",
    "    CLASS_LABELS = [0, 1]\n",
    "\n",
    "    # Separate indices by class\n",
    "    class_indices = {label: [idx for idx in indices if labels[idx] == label] for label in CLASS_LABELS}\n",
    "\n",
    "    # Determine the minimum class count\n",
    "    min_class_count = min(len(indices) for indices in class_indices.values())\n",
    "\n",
    "    # Adjust class balance by undersampling the majority class\n",
    "    balanced_indices = []\n",
    "    for label, class_list in class_indices.items():\n",
    "        if len(class_list) > min_class_count:\n",
    "            sampled_indices = np.random.choice(class_list, size=min_class_count, replace=False)\n",
    "            balanced_indices.extend(sampled_indices)\n",
    "        else:\n",
    "            balanced_indices.extend(class_list)\n",
    "\n",
    "    # Shuffle the indices for randomization\n",
    "    np.random.shuffle(balanced_indices)\n",
    "    return np.array(balanced_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified cross-validation setup for model training and validation\n",
    "\n",
    "Set up stratified 10-fold cross-validation for each site (excluding `test_site`) to evaluate model performance across multiple splits. Here’s an overview of the process:\n",
    "\n",
    "**Stratified k-folds**: StratifiedKFold let to maintain the balance of classes (ASD vs. NC) across each fold, reducing potential bias.\n",
    "\n",
    "**Fold processing**: For each site, 10 training and validation folds are generated, and indices are stored in the `train_indices` and `val_indices` dictionaries. To ensure class balance after combining all group folds for training data the majority class in each site is undersampling.\n",
    "\n",
    "**Class balance checks**: For each fold, the balance of ASD and NC samples is shown to confirm each split maintains similar distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold #0 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #1 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #2 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #3 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #4 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #5 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #6 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #7 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #8 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `caltech`\n",
      "Balance of classes in training -> ASD: 17 and TC: 17\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `cmu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #1 for site `cmu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #2 for site `cmu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #3 for site `cmu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #4 for site `cmu`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #5 for site `cmu`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #6 for site `cmu`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `cmu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `cmu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `cmu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `kki`\n",
      "Balance of classes in training -> ASD: 20 and TC: 20\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #1 for site `kki`\n",
      "Balance of classes in training -> ASD: 20 and TC: 20\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #2 for site `kki`\n",
      "Balance of classes in training -> ASD: 20 and TC: 20\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #3 for site `kki`\n",
      "Balance of classes in training -> ASD: 19 and TC: 19\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #4 for site `kki`\n",
      "Balance of classes in training -> ASD: 19 and TC: 19\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #5 for site `kki`\n",
      "Balance of classes in training -> ASD: 20 and TC: 20\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #6 for site `kki`\n",
      "Balance of classes in training -> ASD: 20 and TC: 20\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #7 for site `kki`\n",
      "Balance of classes in training -> ASD: 20 and TC: 20\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #8 for site `kki`\n",
      "Balance of classes in training -> ASD: 20 and TC: 20\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #9 for site `kki`\n",
      "Balance of classes in training -> ASD: 20 and TC: 20\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #0 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #1 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #2 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #3 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #4 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #5 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #6 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `leuven_1`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #1 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #2 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #3 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #4 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #5 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #6 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `leuven_2`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 21 and TC: 21\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #1 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 21 and TC: 21\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #2 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 21 and TC: 21\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #3 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 21 and TC: 21\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #4 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #5 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #6 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #7 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #8 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #9 for site `max_mun`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #0 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #1 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #2 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #3 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #4 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #5 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #6 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #7 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #8 for site `nyu`\n",
      "Balance of classes in training -> ASD: 71 and TC: 71\n",
      "Balance of classes in validation -> ASD: 8 and TC: 8\n",
      "Processing fold #9 for site `nyu`\n",
      "Balance of classes in training -> ASD: 72 and TC: 72\n",
      "Balance of classes in validation -> ASD: 7 and TC: 7\n",
      "Processing fold #0 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #1 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #2 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #3 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #4 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #5 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #6 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `ohsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `olin`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #1 for site `olin`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #2 for site `olin`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #3 for site `olin`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #4 for site `olin`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #5 for site `olin`\n",
      "Balance of classes in training -> ASD: 14 and TC: 14\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #6 for site `olin`\n",
      "Balance of classes in training -> ASD: 15 and TC: 15\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `olin`\n",
      "Balance of classes in training -> ASD: 15 and TC: 15\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `olin`\n",
      "Balance of classes in training -> ASD: 15 and TC: 15\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `olin`\n",
      "Balance of classes in training -> ASD: 15 and TC: 15\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `pitt`\n",
      "Balance of classes in training -> ASD: 24 and TC: 24\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #1 for site `pitt`\n",
      "Balance of classes in training -> ASD: 24 and TC: 24\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #2 for site `pitt`\n",
      "Balance of classes in training -> ASD: 24 and TC: 24\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #3 for site `pitt`\n",
      "Balance of classes in training -> ASD: 24 and TC: 24\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #4 for site `pitt`\n",
      "Balance of classes in training -> ASD: 24 and TC: 24\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #5 for site `pitt`\n",
      "Balance of classes in training -> ASD: 24 and TC: 24\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #6 for site `pitt`\n",
      "Balance of classes in training -> ASD: 24 and TC: 24\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #7 for site `pitt`\n",
      "Balance of classes in training -> ASD: 25 and TC: 25\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #8 for site `pitt`\n",
      "Balance of classes in training -> ASD: 25 and TC: 25\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #9 for site `pitt`\n",
      "Balance of classes in training -> ASD: 25 and TC: 25\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #0 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #1 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #2 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #3 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #4 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #5 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #6 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `sbl`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #1 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #2 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #3 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #4 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #5 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #6 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `sdsu`\n",
      "Balance of classes in training -> ASD: 13 and TC: 13\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #1 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #2 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #3 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #4 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #5 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #6 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #7 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #8 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #9 for site `stanford`\n",
      "Balance of classes in training -> ASD: 18 and TC: 18\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #0 for site `trinity`\n",
      "Balance of classes in training -> ASD: 21 and TC: 21\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #1 for site `trinity`\n",
      "Balance of classes in training -> ASD: 21 and TC: 21\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #2 for site `trinity`\n",
      "Balance of classes in training -> ASD: 21 and TC: 21\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #3 for site `trinity`\n",
      "Balance of classes in training -> ASD: 21 and TC: 21\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #4 for site `trinity`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #5 for site `trinity`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #6 for site `trinity`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #7 for site `trinity`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #8 for site `trinity`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #9 for site `trinity`\n",
      "Balance of classes in training -> ASD: 22 and TC: 22\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #0 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 29 and TC: 29\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #1 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 28 and TC: 28\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n",
      "Processing fold #2 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 28 and TC: 28\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n",
      "Processing fold #3 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 29 and TC: 29\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #4 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 29 and TC: 29\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #5 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 29 and TC: 29\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #6 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 29 and TC: 29\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #7 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 29 and TC: 29\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #8 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 29 and TC: 29\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #9 for site `ucla_1`\n",
      "Balance of classes in training -> ASD: 29 and TC: 29\n",
      "Balance of classes in validation -> ASD: 3 and TC: 3\n",
      "Processing fold #0 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #1 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #2 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #3 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #4 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #5 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #6 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `ucla_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `um_1`\n",
      "Balance of classes in training -> ASD: 47 and TC: 47\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #1 for site `um_1`\n",
      "Balance of classes in training -> ASD: 47 and TC: 47\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #2 for site `um_1`\n",
      "Balance of classes in training -> ASD: 47 and TC: 47\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #3 for site `um_1`\n",
      "Balance of classes in training -> ASD: 48 and TC: 48\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #4 for site `um_1`\n",
      "Balance of classes in training -> ASD: 48 and TC: 48\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #5 for site `um_1`\n",
      "Balance of classes in training -> ASD: 48 and TC: 48\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #6 for site `um_1`\n",
      "Balance of classes in training -> ASD: 48 and TC: 48\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #7 for site `um_1`\n",
      "Balance of classes in training -> ASD: 48 and TC: 48\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #8 for site `um_1`\n",
      "Balance of classes in training -> ASD: 48 and TC: 48\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #9 for site `um_1`\n",
      "Balance of classes in training -> ASD: 48 and TC: 48\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #0 for site `um_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #1 for site `um_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #2 for site `um_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #3 for site `um_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #4 for site `um_2`\n",
      "Balance of classes in training -> ASD: 11 and TC: 11\n",
      "Balance of classes in validation -> ASD: 2 and TC: 2\n",
      "Processing fold #5 for site `um_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #6 for site `um_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #7 for site `um_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #8 for site `um_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #9 for site `um_2`\n",
      "Balance of classes in training -> ASD: 12 and TC: 12\n",
      "Balance of classes in validation -> ASD: 1 and TC: 1\n",
      "Processing fold #0 for site `usm`\n",
      "Balance of classes in training -> ASD: 38 and TC: 38\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #1 for site `usm`\n",
      "Balance of classes in training -> ASD: 38 and TC: 38\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #2 for site `usm`\n",
      "Balance of classes in training -> ASD: 38 and TC: 38\n",
      "Balance of classes in validation -> ASD: 5 and TC: 5\n",
      "Processing fold #3 for site `usm`\n",
      "Balance of classes in training -> ASD: 39 and TC: 39\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n",
      "Processing fold #4 for site `usm`\n",
      "Balance of classes in training -> ASD: 39 and TC: 39\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n",
      "Processing fold #5 for site `usm`\n",
      "Balance of classes in training -> ASD: 39 and TC: 39\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n",
      "Processing fold #6 for site `usm`\n",
      "Balance of classes in training -> ASD: 39 and TC: 39\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n",
      "Processing fold #7 for site `usm`\n",
      "Balance of classes in training -> ASD: 39 and TC: 39\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n",
      "Processing fold #8 for site `usm`\n",
      "Balance of classes in training -> ASD: 39 and TC: 39\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n",
      "Processing fold #9 for site `usm`\n",
      "Balance of classes in training -> ASD: 39 and TC: 39\n",
      "Balance of classes in validation -> ASD: 4 and TC: 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Number of cross-validation folds\n",
    "n_folds = 10\n",
    "\n",
    "# Dictionaries for save the training and validation indices\n",
    "train_indices = {}\n",
    "val_indices = {}\n",
    "\n",
    "# Perform stratified k-fold cross-validation for each site, excluding 'test_site' for testing\n",
    "for site in sites:\n",
    "    if site == test_site:\n",
    "        continue\n",
    "\n",
    "    features = rois_time_series[site]\n",
    "    labels = rois_labels[site]\n",
    "\n",
    "    # Initialize StratifiedKFold with shuffle to ensure data randomization\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "    \n",
    "    site_train_indices = []\n",
    "    site_val_indices = []\n",
    "\n",
    "    # Loop through each fold in the stratified split\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(features, labels)):\n",
    "        print(f\"Processing fold #{fold} for site `{site}`\")\n",
    "      \n",
    "        train_idx = adjust_class_balance(train_idx, labels)\n",
    "        val_idx = adjust_class_balance(val_idx, labels)\n",
    "\n",
    "        # Append training and validation indices for each fold\n",
    "        site_train_indices.append(np.array(train_idx))\n",
    "        site_val_indices.append(np.array(val_idx))\n",
    "        \n",
    "        # Print class distribution for training and validation sets for each fold\n",
    "        print(f\"Balance of classes in training -> ASD: {np.count_nonzero(labels[site_train_indices[fold]] == 1)} and TC: {np.count_nonzero(labels[site_train_indices[fold]] == 0)}\")\n",
    "        \n",
    "        print(f\"Balance of classes in validation -> ASD: {np.count_nonzero(labels[site_val_indices[fold]] == 1)} and TC: {np.count_nonzero(labels[site_val_indices[fold]] == 0)}\")\n",
    "\n",
    "    # Store indices for each fold in the dictionaries\n",
    "    train_indices[site] = site_train_indices\n",
    "    val_indices[site] = site_val_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluation metrics function\n",
    "\n",
    "Definition of the `calculate_metrics(y_true, y_pred, y_pred_prob)` function to evaluate the performance of a binary classification model. The function computes several key metrics using true labels (y_true), predicted labels (y_pred), and predicted probabilities (y_pred_prob). These metrics include:\n",
    "\n",
    "**Accuracy**: The proportion of correct predictions among all predictions.\n",
    "\n",
    "**Sensitivity (Recall)**: The ability to correctly identify positive cases.\n",
    "\n",
    "**Precision**: The proportion of true positive predictions among all positive predictions.\n",
    "**Specificity**: The ability to correctly identify negative cases.\n",
    "\n",
    "**Area Under the Curve (AUC)**: Measures the ability of the model to distinguish between classes.\n",
    "**Confusion Matrix**: Summarizes true/false positives and negatives.\n",
    "\n",
    "The function handles edge cases where division by zero might occur, ensuring stability in metric computation. This is essential for evaluating the performance of deep learning models in ASD classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_pred_prob):\n",
    "    \"\"\"\n",
    "    Calculate key evaluation metrics for binary classification tasks.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        Ground truth (true labels).\n",
    "    y_pred : array-like\n",
    "        Predicted labels (binary).\n",
    "    y_pred_prob : array-like\n",
    "        Predicted probabilities for the positive class.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    accuracy : float\n",
    "        Proportion of correctly predicted instances.\n",
    "    sensitivity : float\n",
    "        True positive rate (recall for the positive class).\n",
    "    precision : float\n",
    "        Precision for the positive class.\n",
    "    specificity : float\n",
    "        True negative rate (recall for the negative class).\n",
    "    auc : float\n",
    "        Area Under the Receiver Operating Characteristic Curve (ROC AUC).\n",
    "    cm : ndarray\n",
    "        Confusion matrix as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix and unpack values\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate metrics with safeguards against division by zero\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    \n",
    "    return accuracy, sensitivity, precision, specificity, auc, cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to print metrics\n",
    "Definition of the `print_metrics(split, dataset_type, accuracy, sensitivity, precision, specificity, auc, cm)` function, which displays key evaluation metrics for a specific dataset split and type. The function is designed to enhance interpretability during model evaluation by printing the following metrics in a well-formatted manner:\n",
    "\n",
    "**Accuracy**: The overall correctness of predictions.\n",
    "\n",
    "**Sensitivity (Recall)**: The ability to correctly detect positive cases.\n",
    "\n",
    "**Precision**: The reliability of positive predictions.\n",
    "\n",
    "**Specificity**: The ability to correctly detect negative cases.\n",
    "\n",
    "**AUC-ROC Score**: The model’s ability to distinguish between positive and negative classes.\n",
    "\n",
    "**Confusion Matrix**: A tabular summary of prediction outcomes (true positives, false positives, etc.).\n",
    "\n",
    "The parameters allow for flexible use across various dataset types (e.g., training, validation, test) and splits during cross-validation. For example, split helps track metrics for a specific fold in k-fold cross-validation, while dataset_type differentiates between datasets. The metrics are displayed as percentages for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(split, dataset_type, accuracy, sensitivity, precision, specificity, auc, cm):\n",
    "    \"\"\"\n",
    "    Display evaluation metrics for a specific data split and dataset type.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    split : int\n",
    "        The current split index (zero-based).\n",
    "    dataset_type : str\n",
    "        The type of dataset (e.g., \"training\", \"validation\", \"test\").\n",
    "    accuracy : float\n",
    "        Proportion of correctly predicted instances.\n",
    "    sensitivity : float\n",
    "        True positive rate (recall for the positive class).\n",
    "    precision : float\n",
    "        Precision for the positive class.\n",
    "    specificity : float\n",
    "        True negative rate (recall for the negative class).\n",
    "    auc : float\n",
    "        Area Under the Receiver Operating Characteristic Curve (ROC AUC).\n",
    "    cm : ndarray\n",
    "        Confusion matrix as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(f\"\\n{dataset_type.capitalize()} Metrics for Split {split + 1}:\")\n",
    "    print(f\"  Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"  Sensitivity (Recall): {sensitivity * 100:.2f}%\")\n",
    "    print(f\"  Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"  Specificity: {specificity * 100:.2f}%\")\n",
    "    print(f\"  AUC-ROC Score: {auc * 100:.2f}%\")\n",
    "    print(f\"  Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving tangent spaces\n",
    "\n",
    "Prepare connectivity matrices in the tangent space representation for each fold of cross-validation.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "**Initialization**: The `connectivity_list` is created to store tangent space representations for each split.\n",
    "\n",
    "**Cross-validation Loop**:\n",
    "Iterates through each fold defined by n_folds.\n",
    "Initializes lists to store training and validation time series data (`X_train_time_series`, `X_val_time_series`) and their corresponding labels (`y_train`, `y_val`).\n",
    "\n",
    "**Site-Specific Aggregation**:\n",
    "For each site, the function aggregates data while excluding the predefined `test_site` for external testing.\n",
    "Training and validation data are selected based on indices for the current split.\n",
    "\n",
    "**Tangent Space Representation**:\n",
    "The estimate_tangent_space function is applied to the training data to extract the tangent space representation, which is then appended to `connectivity_list`.\n",
    "**Output**:\n",
    "\n",
    "A list of tangent space representations (`connectivity_list`) for training data across all cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Split 1 ---\n",
      "\n",
      "--- Split 2 ---\n",
      "\n",
      "--- Split 3 ---\n",
      "\n",
      "--- Split 4 ---\n",
      "\n",
      "--- Split 5 ---\n",
      "\n",
      "--- Split 6 ---\n",
      "\n",
      "--- Split 7 ---\n",
      "\n",
      "--- Split 8 ---\n",
      "\n",
      "--- Split 9 ---\n",
      "\n",
      "--- Split 10 ---\n"
     ]
    }
   ],
   "source": [
    "connectivity_list = []\n",
    "\n",
    "# Perform cross-validation across all splits\n",
    "for split in range(n_folds):\n",
    "    print(f\"\\n--- Split {split + 1} ---\")\n",
    "\n",
    "    # Initialize lists for training and validation data\n",
    "    X_train_time_series, X_val_time_series = [], []\n",
    "    y_train, y_val = [], []\n",
    "\n",
    "    # Aggregate data from all sites except the test site\n",
    "    for site in sites:\n",
    "        if site == test_site:  # Skip the test site\n",
    "            continue\n",
    "\n",
    "        # Add training data for the current split\n",
    "        X_train_time_series.extend(\n",
    "            rois_time_series[site][idx] for idx in train_indices[site][split]\n",
    "        )\n",
    "        y_train.extend(\n",
    "            rois_labels[site][idx] for idx in train_indices[site][split]\n",
    "        )\n",
    "\n",
    "        # Add validation data for the current split\n",
    "        X_val_time_series.extend(\n",
    "            rois_time_series[site][idx] for idx in val_indices[site][split]\n",
    "        )\n",
    "        y_val.extend(\n",
    "            rois_labels[site][idx] for idx in val_indices[site][split]\n",
    "        )\n",
    "\n",
    "    # Estimate tangent space representation for training data\n",
    "    connectivity_m = estimate_tangent_space(X_train_time_series)\n",
    "    connectivity_list.append(connectivity_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'connectivity_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mconnectivity_list\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'connectivity_list' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(connectivity_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, validation and testing DNN\n",
    "\n",
    "Training, validating, and testing a DL model using cross-validation. It calculates and aggregates performance metrics across all folds, culminating in mean metrics for both validation and test datasets.\n",
    "\n",
    "1. **Initialization**:\n",
    "   - A `metrics` dictionary is initialized to store cumulative performance metrics (accuracy, sensitivity, precision, specificity, and AUC) for validation and test datasets.\n",
    "\n",
    "2. **Cross-Validation Process**:\n",
    "   - The loop iterates over the number of folds (`n_folds`), performing the following steps for each split:\n",
    "     - **Data Aggregation**:\n",
    "       - Training and validation data are collected across all sites, excluding the test site. Functional connectivity features are prepared by transforming time series data into tangent space representations.\n",
    "     - **Dataset Preparation**:\n",
    "       - The training, validation, and test datasets are converted into NumPy arrays for compatibility with the model.\n",
    "     - **Dataset Statistics**:\n",
    "       - The shapes and class distributions of the datasets are printed for transparency.\n",
    "\n",
    "3. **Model Training**:\n",
    "   - A DNN model is built and trained on the training dataset (`X_train`, `y_train`). Validation data (`X_val`, `y_val`) is used to monitor the training process.\n",
    "\n",
    "4. **Evaluation**:\n",
    "   - **Validation Set**:\n",
    "     - Predictions are generated, and metrics are calculated using a helper function (`calculate_metrics`). Results are printed and added to the cumulative metrics for validation.\n",
    "   - **Test Set**:\n",
    "     - The same process is applied to evaluate the model on the test dataset. Results are added to the cumulative metrics for the test.\n",
    "\n",
    "5. **Mean Metric Calculation**:\n",
    "   - After completing all splits, mean performance metrics are calculated for both validation and test datasets by dividing cumulative values by the number of folds (`n_folds`).\n",
    "\n",
    "6. **Output**:\n",
    "   - The mean metrics for validation and test datasets are printed, summarizing the model’s performance across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize accumulators for metrics\n",
    "metrics = {\n",
    "    \"validation\": {\"accuracy\": 0, \"sensitivity\": 0, \"precision\": 0, \"specificity\": 0, \"auc\": 0},\n",
    "    \"test\": {\"accuracy\": 0, \"sensitivity\": 0, \"precision\": 0, \"specificity\": 0, \"auc\": 0}\n",
    "}\n",
    "\n",
    "# Cross-validation across all splits\n",
    "for split in range(n_folds):\n",
    "    print(f\"\\n--- Split {split + 1} ---\")\n",
    "\n",
    "    # Aggregate training and validation data across all sites\n",
    "    X_train_time_series, X_val_time_series = [], []\n",
    "    y_train, y_val = [], []\n",
    "\n",
    "    for site in sites:\n",
    "        if site == test_site:\n",
    "            continue\n",
    "        X_train_time_series.extend([rois_time_series[site][idx] for idx in train_indices[site][split]])\n",
    "        y_train.extend([rois_labels[site][idx] for idx in train_indices[site][split]])\n",
    "        X_val_time_series.extend([rois_time_series[site][idx] for idx in val_indices[site][split]])\n",
    "        y_val.extend([rois_labels[site][idx] for idx in val_indices[site][split]])\n",
    "\n",
    "    # Prepare tangent space for feature extraction\n",
    "    X_train = connectivity_list[split].transform(X_train_time_series)\n",
    "    X_val = connectivity_list[split].transform(X_val_time_series)\n",
    "    X_test = connectivity_list[split].transform(rois_time_series[test_site])\n",
    "    y_test = rois_labels[test_site]\n",
    "\n",
    "    X_train, X_val, X_test = map(np.array, [X_train, X_val, X_test])\n",
    "    y_train, y_val, y_test = map(np.array, [y_train, y_val, y_test])\n",
    "\n",
    "    # Print dataset statistics\n",
    "    print(f\"Training set shape: {X_train.shape}, class balance: ASD={np.sum(y_train == 1)}, TC={np.sum(y_train == 0)}\")\n",
    "    print(f\"Validation set shape: {X_val.shape}, class balance: ASD={np.sum(y_val == 1)}, TC={np.sum(y_val == 0)}\")\n",
    "    print(f\"Test set shape: {X_test.shape}, class balance: ASD={np.sum(y_test == 1)}, TC={np.sum(y_test == 0)}\")\n",
    "\n",
    "    # Build and train the model\n",
    "    dnn = build_model(X_train.shape[1])\n",
    "    history = dnn.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=100, callbacks=callbacks_list)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    validation_pred_prob = dnn.predict(X_val).ravel()\n",
    "    validation_pred = (validation_pred_prob > 0.5).astype(int)\n",
    "    acc, sens, prec, spec, auc, cm = calculate_metrics(y_val, validation_pred, validation_pred_prob)\n",
    "    metrics[\"validation\"][\"accuracy\"] += acc\n",
    "    metrics[\"validation\"][\"sensitivity\"] += sens\n",
    "    metrics[\"validation\"][\"precision\"] += prec\n",
    "    metrics[\"validation\"][\"specificity\"] += spec\n",
    "    metrics[\"validation\"][\"auc\"] += auc\n",
    "    print_metrics(split, \"validation\", acc, sens, prec, spec, auc, cm)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_pred_prob = dnn.predict(X_test).ravel()\n",
    "    test_pred = (test_pred_prob > 0.5).astype(int)\n",
    "    acc, sens, prec, spec, auc, cm = calculate_metrics(y_test, test_pred, test_pred_prob)\n",
    "    metrics[\"test\"][\"accuracy\"] += acc\n",
    "    metrics[\"test\"][\"sensitivity\"] += sens\n",
    "    metrics[\"test\"][\"precision\"] += prec\n",
    "    metrics[\"test\"][\"specificity\"] += spec\n",
    "    metrics[\"test\"][\"auc\"] += auc\n",
    "    print_metrics(split, \"test\", acc, sens, prec, spec, auc, cm)\n",
    "\n",
    "# Print mean metrics\n",
    "for dataset in metrics:\n",
    "    print(f\"\\n--- Mean {dataset.capitalize()} Metrics Across All Splits ---\")\n",
    "    for metric, value in metrics[dataset].items():\n",
    "        print(f\"{metric.capitalize()}: {(value / n_folds) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, validation and testing DNN with the whole dataset\n",
    "\n",
    "Prepares the training and test datasets for the classification model by aggregating data from all sites except the test site and transforming the functional connectivity matrices into feature vectors using tangent space parametrization.\n",
    "\n",
    "1. **Data Aggregation**:\n",
    "   - The time-series data (`rois_time_series`) and corresponding labels (`rois_labels`) from all sites, except the designated `test_site`, are combined into `X_train_time_series` and `y_data`, respectively.\n",
    "\n",
    "2. **Tangent Space Preparation**:\n",
    "   - A tangent space model is estimated using the training time-series data by calling the `estimate_tangent_space` function. This step prepares a feature extraction mechanism for transforming the raw data.\n",
    "\n",
    "3. **Feature Transformation**:\n",
    "   - The tangent space model is applied to both:\n",
    "     - `X_train_time_series` to transform training data into feature vectors stored in `X_data`.\n",
    "     - `rois_time_series[test_site]` to transform the test site data into feature vectors stored in `X_test`.\n",
    "   - The labels for the test set are stored in `y_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Aggregate all training data\n",
    "X_train_time_series, y_data = [], []\n",
    "\n",
    "for site in sites:\n",
    "    if site == test_site:\n",
    "        continue\n",
    "\n",
    "    X_train_time_series.extend(rois_time_series[site])\n",
    "    y_data.extend(rois_labels[site])\n",
    "\n",
    "# Prepare tangent space for feature extraction\n",
    "connectivity_m = estimate_tangent_space(X_train_time_series)\n",
    "print(\"Tangent space estimated.\")\n",
    "\n",
    "# Transform data into feature vectors\n",
    "X_data = connectivity_m.transform(X_train_time_series)\n",
    "X_test = connectivity_m.transform(rois_time_series[test_site])\n",
    "y_test = rois_labels[test_site]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handles the data preparation, model training, and evaluation on training, validation, and test datasets.\n",
    "\n",
    "1. **Splitting the Data**:\n",
    "   - The training data (`X_data`, `y_data`) is split into training (`X_train`, `y_train`) and validation (`X_val`, `y_val`) sets using `train_test_split` with stratification to preserve class balance.\n",
    "   - The test set remains separate as `X_test` and `y_test`.\n",
    "\n",
    "2. **Data Conversion**:\n",
    "   - Training, validation, and test datasets (`X_train`, `X_val`, `X_test`, `y_train`, `y_val`, `y_test`) are converted to numpy arrays for compatibility with the model.\n",
    "\n",
    "3. **Dataset Statistics**:\n",
    "   - Prints the shapes of the training, validation, and test sets along with the class distribution for `ASD` (positive class) and `TC` (negative class).\n",
    "\n",
    "4. **Model Training**:\n",
    "   - A deep neural network (DNN) is constructed using the `build_model` function, with the input shape derived from `X_train`.\n",
    "   - The model is trained on the training set (`X_train`, `y_train`) and evaluated on the validation set (`X_val`, `y_val`) using:\n",
    "     - Batch size: 32\n",
    "     - Epochs: 100\n",
    "     - Callbacks: `callbacks_list` for monitoring and early stopping.\n",
    "\n",
    "5. **Evaluation**:\n",
    "   - Predictions and metrics (accuracy, sensitivity, precision, specificity, AUC) are calculated for the following sets:\n",
    "     - **Training Set**:\n",
    "       - Predictions: `train_pred_prob`, thresholded at 0.5 for binary classification.\n",
    "       - Metrics calculated using `calculate_metrics` and printed using `print_metrics`.\n",
    "     - **Validation Set**:\n",
    "       - Predictions: `val_pred_prob`, thresholded at 0.5 for binary classification.\n",
    "       - Metrics calculated and printed as above.\n",
    "     - **Test Set**:\n",
    "       - Predictions: `test_pred_prob`, thresholded at 0.5 for binary classification.\n",
    "       - Metrics calculated and printed as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, stratify=y_data, test_size=0.2)\n",
    "\n",
    "# Convert labels to numpy arrays\n",
    "X_train, X_val, X_test = map(np.array, [X_train, X_val, X_test])\n",
    "y_train, y_val, y_test = map(np.array, [y_train, y_val, y_test])\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Training set shape: {X_train.shape}, class balance: ASD={np.sum(y_train == 1)}, TC={np.sum(y_train == 0)}\")\n",
    "print(f\"Validation set shape: {X_val.shape}, class balance: ASD={np.sum(y_val == 1)}, TC={np.sum(y_val == 0)}\")\n",
    "print(f\"Test set shape: {X_test.shape}, class balance: ASD={np.sum(y_test == 1)}, TC={np.sum(y_test == 0)}\")\n",
    "\n",
    "# Build and train the model\n",
    "dnn = build_model(X_train.shape[1])\n",
    "history = dnn.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=100, callbacks=callbacks_list)\n",
    "\n",
    "# Evaluate on training set\n",
    "train_pred_prob = dnn.predict(X_train).ravel()\n",
    "train_pred = (train_pred_prob > 0.5).astype(int)\n",
    "acc, sens, prec, spec, auc, cm = calculate_metrics(y_train, train_pred, train_pred_prob)\n",
    "print_metrics(1, \"training\", acc, sens, prec, spec, auc, cm)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_pred_prob = dnn.predict(X_val).ravel()\n",
    "val_pred = (val_pred_prob > 0.5).astype(int)\n",
    "acc, sens, prec, spec, auc, cm = calculate_metrics(y_val, val_pred, val_pred_prob)\n",
    "print_metrics(1, \"validation\", acc, sens, prec, spec, auc, cm)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_pred_prob = dnn.predict(X_test).ravel()\n",
    "test_pred = (test_pred_prob > 0.5).astype(int)\n",
    "acc, sens, prec, spec, auc, cm = calculate_metrics(y_test, test_pred, test_pred_prob)\n",
    "print_metrics(1, \"test\", acc, sens, prec, spec, auc, cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
